{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor\n",
    "\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_examples(N=50,L=10):\n",
    "    examples = []\n",
    "    labels = []\n",
    "    for n in xrange(N):\n",
    "        pp = numpy.random.rand()\n",
    "        ex = []\n",
    "        for l in xrange(L):\n",
    "            if numpy.random.rand() < pp:\n",
    "                ex.append(0)\n",
    "            else:\n",
    "                ex.append(1)\n",
    "        labels.append(numpy.sum(ex))\n",
    "        examples.append(ex)\n",
    "    return examples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create some toy datasets\n",
    "all_x, all_y = create_examples(400, 10)\n",
    "train_x, train_y = all_x[:300], all_y[:300]\n",
    "valid_x, valid_y = all_x[300:350], all_y[300:350]\n",
    "test_x, test_y = all_x[350:], all_y[350:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a recursive function\n",
    "def f_rec(x_, h_, U):\n",
    "    h_new = tensor.tanh(x_ + tensor.dot(h_, U))\n",
    "    return h_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_memory = 5\n",
    "d_input = 2\n",
    "\n",
    "# initialize the parameter nodes\n",
    "W = theano.shared(0.1 * numpy.random.randn(d_input, d_memory).astype('float32'))\n",
    "U = theano.shared(0.1 * numpy.random.randn(d_memory, d_memory).astype('float32'))\n",
    "V = theano.shared(numpy.random.randn(d_memory).astype('float32'))\n",
    "\n",
    "# initialize the input and output nodes\n",
    "x = tensor.vector(dtype='int64')\n",
    "y = tensor.scalar(dtype='int64')\n",
    "\n",
    "# build a computational graph\n",
    "x_emb = W[x]\n",
    "h, updates = theano.scan(f_rec, x_emb, outputs_info=[tensor.alloc(0., d_memory)], non_sequences=[U])\n",
    "y_pred = tensor.nnet.softplus(tensor.dot(h[-1], V))\n",
    "\n",
    "# define an empirical cost function\n",
    "cost = ((y - y_pred)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prediction function\n",
    "f_pred = theano.function([x], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost function\n",
    "f_cost = theano.function([x,y], cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute gradient with the reverse mode automatic differentiation\n",
    "grad0 = theano.grad(cost, [W, U, V])\n",
    "f_grad = theano.function([x,y], grad0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gradient clipping\n",
    "clip = 1.\n",
    "grad_norm = tensor.sum([(g**2).sum() for g in grad0])\n",
    "grad = [tensor.switch(grad_norm > clip ** 2, \n",
    "                      g / tensor.sqrt(grad_norm) * clip, g) for g in grad0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# update rule\n",
    "lrate = tensor.scalar(dtype='float32')\n",
    "f_update = theano.function([x, y, lrate], [cost], \n",
    "                           updates={(W, W-lrate*grad[0]), \n",
    "                                    (U, U-lrate*grad[1]),\n",
    "                                    (V, V-lrate*grad[2])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train Cost 27.020450751 Validation Cost 24.7816032554 Validation Error 0.92\n",
      "Epoch 10 Train Cost 2.44860515717 Validation Cost 2.32291115537 Validation Error 0.76\n",
      "Epoch 20 Train Cost 0.202131001106 Validation Cost 0.353881515281 Validation Error 0.48\n",
      "Epoch 30 Train Cost 0.0989434779367 Validation Cost 0.167754565449 Validation Error 0.32\n",
      "Epoch 40 Train Cost 0.107455457035 Validation Cost 0.0922564752643 Validation Error 0.08\n",
      "Epoch 50 Train Cost 0.0876225755292 Validation Cost 0.10500823707 Validation Error 0.14\n",
      "Epoch 60 Train Cost 0.0687496820036 Validation Cost 0.0648581382768 Validation Error 0.1\n",
      "Epoch 70 Train Cost 0.0770556380988 Validation Cost 0.13337330856 Validation Error 0.18\n",
      "Epoch 80 Train Cost 0.0744899941375 Validation Cost 0.0563583147246 Validation Error 0.08\n",
      "Epoch 90 Train Cost 0.0554657230202 Validation Cost 0.0833183467301 Validation Error 0.08\n",
      "Epoch 100 Train Cost 0.0626825154783 Validation Cost 0.150683822951 Validation Error 0.22\n",
      "Epoch 110 Train Cost 0.0540904915761 Validation Cost 0.0443085067591 Validation Error 0.04\n",
      "Epoch 120 Train Cost 0.0602538517964 Validation Cost 0.0518872354672 Validation Error 0.06\n",
      "Epoch 130 Train Cost 0.0576901974449 Validation Cost 0.044110177367 Validation Error 0.06\n",
      "Epoch 140 Train Cost 0.0724133695972 Validation Cost 0.078221400584 Validation Error 0.08\n",
      "Epoch 150 Train Cost 0.048511053613 Validation Cost 0.0550670161651 Validation Error 0.08\n",
      "Epoch 160 Train Cost 0.0574510225917 Validation Cost 0.0477684765147 Validation Error 0.06\n",
      "Epoch 170 Train Cost 0.0568034100543 Validation Cost 0.035306787065 Validation Error 0.0\n",
      "Epoch 180 Train Cost 0.0541514769359 Validation Cost 0.0487200179603 Validation Error 0.06\n",
      "Epoch 190 Train Cost 0.0823788427793 Validation Cost 0.0482880412924 Validation Error 0.04\n",
      "Epoch 200 Train Cost 0.0442208766227 Validation Cost 0.0263733337672 Validation Error 0.0\n",
      "Epoch 210 Train Cost 0.0585686053447 Validation Cost 0.0273885654478 Validation Error 0.02\n",
      "Epoch 220 Train Cost 0.066642361633 Validation Cost 0.0466893492009 Validation Error 0.04\n",
      "Epoch 230 Train Cost 0.0595200130045 Validation Cost 0.0418096137599 Validation Error 0.04\n",
      "Epoch 240 Train Cost 0.0569127422489 Validation Cost 0.0283692919364 Validation Error 0.02\n",
      "Epoch 250 Train Cost 0.0495677093987 Validation Cost 0.0340045767599 Validation Error 0.04\n",
      "Epoch 260 Train Cost 0.0553182513902 Validation Cost 0.0229458599352 Validation Error 0.0\n",
      "Epoch 270 Train Cost 0.0407326909696 Validation Cost 0.0459384326562 Validation Error 0.06\n",
      "Epoch 280 Train Cost 0.0281525797557 Validation Cost 0.0622458687659 Validation Error 0.06\n",
      "Epoch 290 Train Cost 0.0266887694713 Validation Cost 0.060536804033 Validation Error 0.02\n",
      "Epoch 300 Train Cost 0.0320628023645 Validation Cost 0.0701825210876 Validation Error 0.06\n",
      "Epoch 310 Train Cost 0.024115791997 Validation Cost 0.0550524901905 Validation Error 0.04\n",
      "Epoch 320 Train Cost 0.0265221699292 Validation Cost 0.0721234820016 Validation Error 0.08\n",
      "Early Stop!\n"
     ]
    }
   ],
   "source": [
    "# online stochastic gradient descent \n",
    "n_epochs = 1000\n",
    "lrate0 = 0.01\n",
    "ui = 0\n",
    "\n",
    "W.set_value(0.01 * numpy.random.randn(d_input, d_memory).astype('float32'))\n",
    "U.set_value(0.01 * numpy.random.randn(d_memory, d_memory).astype('float32'))\n",
    "V.set_value(0.01 * numpy.random.randn(d_memory).astype('float32'))\n",
    "\n",
    "verrs = []\n",
    "patience = 5\n",
    "violations = 0\n",
    "\n",
    "train_cost = 0\n",
    "\n",
    "for ei in xrange(n_epochs):\n",
    "    for ti in xrange(len(train_x)):\n",
    "        #lrate = numpy.float32(lrate0 / (1.+.0001 * ui))\n",
    "        lrate = lrate0\n",
    "        xx = numpy.array(train_x[ti])\n",
    "        yy = train_y[ti]\n",
    "        cc = f_update(xx, yy, numpy.float32(lrate))\n",
    "        if ui == 0:\n",
    "            train_cost = cc[0]\n",
    "        else:\n",
    "            train_cost = 0.9 * train_cost + 0.1 * cc[0]\n",
    "        ui += 1\n",
    "    # early stopping based on validation cost\n",
    "    if numpy.mod(ei, 10) == 0:\n",
    "        vcc = 0\n",
    "        verr = 0\n",
    "        for ti in xrange(len(valid_x)):\n",
    "            xx = numpy.array(valid_x[ti])\n",
    "            yy = valid_y[ti]\n",
    "            vcc += f_cost(xx, yy)\n",
    "            yp = f_pred(xx)\n",
    "            if yy != numpy.round(yp):\n",
    "                verr += 1\n",
    "        vcc = vcc / len(valid_x)\n",
    "        print 'Epoch', ei, 'Train Cost', train_cost, 'Validation Cost', vcc, 'Validation Error', (numpy.float(verr) / len(valid_x))\n",
    "        if vcc > 1.1 * numpy.min(verrs+[numpy.Inf]):\n",
    "            violations += 1\n",
    "            if violations > patience:\n",
    "                print 'Early Stop!'\n",
    "                break\n",
    "        else:\n",
    "            violations = 0\n",
    "        verrs.append(vcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cost 0.126750723303 Test Error 0.18\n"
     ]
    }
   ],
   "source": [
    "# test the trained model on the test set\n",
    "tcc = 0\n",
    "terr = 0\n",
    "for ti in xrange(len(test_x)):\n",
    "    xx = numpy.array(test_x[ti])\n",
    "    yy = test_y[ti]\n",
    "    tcc += f_cost(xx, yy)\n",
    "    yp = f_pred(xx)\n",
    "    if yy != numpy.round(yp):\n",
    "        terr += 1\n",
    "tcc = tcc / len(test_x)\n",
    "print 'Test Cost', tcc, 'Test Error', (numpy.float(terr) / len(test_x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
